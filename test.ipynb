{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# include tools\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "             geo_level_1_id  geo_level_2_id  geo_level_3_id  \\\nbuilding_id                                                   \n802906                    6             487           12198   \n28830                     8             900            2812   \n94947                    21             363            8973   \n\n             count_floors_pre_eq  age  area_percentage  height_percentage  \\\nbuilding_id                                                                 \n802906                         2   30                6                  5   \n28830                          2   10                8                  7   \n94947                          2   10                5                  5   \n\n            land_surface_condition foundation_type roof_type  ...  \\\nbuilding_id                                                   ...   \n802906                           t               r         n  ...   \n28830                            o               r         n  ...   \n94947                            t               r         n  ...   \n\n            has_secondary_use_hotel has_secondary_use_rental  \\\nbuilding_id                                                    \n802906                            0                        0   \n28830                             0                        0   \n94947                             0                        0   \n\n            has_secondary_use_institution has_secondary_use_school  \\\nbuilding_id                                                          \n802906                                  0                        0   \n28830                                   0                        0   \n94947                                   0                        0   \n\n             has_secondary_use_industry  has_secondary_use_health_post  \\\nbuilding_id                                                              \n802906                                0                              0   \n28830                                 0                              0   \n94947                                 0                              0   \n\n             has_secondary_use_gov_office  has_secondary_use_use_police  \\\nbuilding_id                                                               \n802906                                  0                             0   \n28830                                   0                             0   \n94947                                   0                             0   \n\n             has_secondary_use_other  damage_grade  \nbuilding_id                                         \n802906                             0             3  \n28830                              0             2  \n94947                              0             3  \n\n[3 rows x 39 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>geo_level_1_id</th>\n      <th>geo_level_2_id</th>\n      <th>geo_level_3_id</th>\n      <th>count_floors_pre_eq</th>\n      <th>age</th>\n      <th>area_percentage</th>\n      <th>height_percentage</th>\n      <th>land_surface_condition</th>\n      <th>foundation_type</th>\n      <th>roof_type</th>\n      <th>...</th>\n      <th>has_secondary_use_hotel</th>\n      <th>has_secondary_use_rental</th>\n      <th>has_secondary_use_institution</th>\n      <th>has_secondary_use_school</th>\n      <th>has_secondary_use_industry</th>\n      <th>has_secondary_use_health_post</th>\n      <th>has_secondary_use_gov_office</th>\n      <th>has_secondary_use_use_police</th>\n      <th>has_secondary_use_other</th>\n      <th>damage_grade</th>\n    </tr>\n    <tr>\n      <th>building_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>802906</th>\n      <td>6</td>\n      <td>487</td>\n      <td>12198</td>\n      <td>2</td>\n      <td>30</td>\n      <td>6</td>\n      <td>5</td>\n      <td>t</td>\n      <td>r</td>\n      <td>n</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>28830</th>\n      <td>8</td>\n      <td>900</td>\n      <td>2812</td>\n      <td>2</td>\n      <td>10</td>\n      <td>8</td>\n      <td>7</td>\n      <td>o</td>\n      <td>r</td>\n      <td>n</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>94947</th>\n      <td>21</td>\n      <td>363</td>\n      <td>8973</td>\n      <td>2</td>\n      <td>10</td>\n      <td>5</td>\n      <td>5</td>\n      <td>t</td>\n      <td>r</td>\n      <td>n</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 39 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data info and path\n",
    "DATA_DIR = Path('data')\n",
    "train_values = pd.read_csv(DATA_DIR / 'train_values.csv', index_col='building_id')\n",
    "train_labels = pd.read_csv(DATA_DIR / 'train_labels.csv', index_col='building_id')\n",
    "test_values = pd.read_csv(DATA_DIR / 'test_values.csv', index_col='building_id')\n",
    "\n",
    "data = train_values.join(train_labels)\n",
    "\n",
    "data.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# for preprocessing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# the model\n",
    "import xgboost as xgb\n",
    "\n",
    "# for combining to preprocess with model training\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "# for optimizing the hyperparameters of the pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 260601 entries, 802906 to 747594\n",
      "Data columns (total 39 columns):\n",
      " #   Column                                  Non-Null Count   Dtype \n",
      "---  ------                                  --------------   ----- \n",
      " 0   geo_level_1_id                          260601 non-null  int64 \n",
      " 1   geo_level_2_id                          260601 non-null  int64 \n",
      " 2   geo_level_3_id                          260601 non-null  int64 \n",
      " 3   count_floors_pre_eq                     260601 non-null  int64 \n",
      " 4   age                                     260601 non-null  int64 \n",
      " 5   area_percentage                         260601 non-null  int64 \n",
      " 6   height_percentage                       260601 non-null  int64 \n",
      " 7   land_surface_condition                  260601 non-null  object\n",
      " 8   foundation_type                         260601 non-null  object\n",
      " 9   roof_type                               260601 non-null  object\n",
      " 10  ground_floor_type                       260601 non-null  object\n",
      " 11  other_floor_type                        260601 non-null  object\n",
      " 12  position                                260601 non-null  object\n",
      " 13  plan_configuration                      260601 non-null  object\n",
      " 14  has_superstructure_adobe_mud            260601 non-null  int64 \n",
      " 15  has_superstructure_mud_mortar_stone     260601 non-null  int64 \n",
      " 16  has_superstructure_stone_flag           260601 non-null  int64 \n",
      " 17  has_superstructure_cement_mortar_stone  260601 non-null  int64 \n",
      " 18  has_superstructure_mud_mortar_brick     260601 non-null  int64 \n",
      " 19  has_superstructure_cement_mortar_brick  260601 non-null  int64 \n",
      " 20  has_superstructure_timber               260601 non-null  int64 \n",
      " 21  has_superstructure_bamboo               260601 non-null  int64 \n",
      " 22  has_superstructure_rc_non_engineered    260601 non-null  int64 \n",
      " 23  has_superstructure_rc_engineered        260601 non-null  int64 \n",
      " 24  has_superstructure_other                260601 non-null  int64 \n",
      " 25  legal_ownership_status                  260601 non-null  object\n",
      " 26  count_families                          260601 non-null  int64 \n",
      " 27  has_secondary_use                       260601 non-null  int64 \n",
      " 28  has_secondary_use_agriculture           260601 non-null  int64 \n",
      " 29  has_secondary_use_hotel                 260601 non-null  int64 \n",
      " 30  has_secondary_use_rental                260601 non-null  int64 \n",
      " 31  has_secondary_use_institution           260601 non-null  int64 \n",
      " 32  has_secondary_use_school                260601 non-null  int64 \n",
      " 33  has_secondary_use_industry              260601 non-null  int64 \n",
      " 34  has_secondary_use_health_post           260601 non-null  int64 \n",
      " 35  has_secondary_use_gov_office            260601 non-null  int64 \n",
      " 36  has_secondary_use_use_police            260601 non-null  int64 \n",
      " 37  has_secondary_use_other                 260601 non-null  int64 \n",
      " 38  damage_grade                            260601 non-null  int64 \n",
      "dtypes: int64(31), object(8)\n",
      "memory usage: 87.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# pipeline and selective features\n",
    "categorical_features = ['land_surface_condition',\n",
    "            'foundation_type',\n",
    "            'roof_type',\n",
    "            'ground_floor_type',\n",
    "            'other_floor_type',\n",
    "            'position',\n",
    "            'plan_configuration',\n",
    "            'legal_ownership_status']\n",
    "\n",
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# preprocess OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_categorical_data = encoder.fit_transform(data[categorical_features])\n",
    "# Merge encoded categorical data with the original dataset and drop the original categorical columns\n",
    "encoded_data = pd.concat([data.drop(categorical_features, axis=1),\n",
    "                          pd.DataFrame(encoded_categorical_data, index=data.index)], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X = encoded_data.drop(['damage_grade'], axis=1)\n",
    "y = encoded_data['damage_grade']\n",
    "# Label conversion, Damage Label (1, 2, 3), need Label (0, 1, 2)\n",
    "y = y - 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier(objective='multi:softmax', num_class=3, seed=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'subsample': 0.9, 'n_estimators': 280, 'max_depth': 10, 'learning_rate': 0.16, 'colsample_bytree': 0.7}\n",
      "Best score found:  0.7453520721412126\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [10],\n",
    "    'learning_rate': [0.12, 0.14, 0.16],\n",
    "    'n_estimators': [240, 250, 260, 270, 280],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.6, 0.7],\n",
    "}\n",
    "\n",
    "# Set up the GridSearchCV object\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_clf,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,  # Number of random combinations to try\n",
    "    scoring='f1_micro',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "random_search.fit(X_train, y_train)\n",
    "# Print the best parameters and corresponding score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best score found: \", random_search.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.7462059438613995\n"
     ]
    }
   ],
   "source": [
    "# Train the final model using the best parameters\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "best_model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=3,\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    subsample=best_params['subsample'],\n",
    "    colsample_bytree=best_params['colsample_bytree'],\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "# Evaluate the model\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "print(\"F1 Score: \", f1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# make prediction on test\n",
    "# preprocess OneHotEncoder\n",
    "test_encoder = OneHotEncoder(sparse=False)\n",
    "test_encoded_categorical_data = encoder.fit_transform(test_values[categorical_features])\n",
    "# Merge encoded categorical data with the original dataset and drop the original categorical columns\n",
    "test_encoded_data = pd.concat([test_values.drop(categorical_features, axis=1),\n",
    "                          pd.DataFrame(test_encoded_categorical_data, index=test_values.index)], axis=1)\n",
    "\n",
    "test_values_pred = best_model.predict(test_encoded_data)\n",
    "test_values_pred = test_values_pred + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "             damage_grade\nbuilding_id              \n300051                  3\n99355                   2\n890251                  2\n745817                  1\n421793                  3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>damage_grade</th>\n    </tr>\n    <tr>\n      <th>building_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>300051</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>99355</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>890251</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>745817</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>421793</th>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save submission\n",
    "submission_format = pd.read_csv(DATA_DIR / 'submission_format.csv', index_col='building_id')\n",
    "my_submission = pd.DataFrame(data=test_values_pred,\n",
    "                             columns=submission_format.columns,\n",
    "                             index=submission_format.index)\n",
    "my_submission.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# save to submission\n",
    "my_submission.to_csv('submission.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}